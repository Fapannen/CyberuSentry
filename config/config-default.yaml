defaults:
  - _self_
  - encoder: eva_tiny
  - datasets: default
  - augmentations: default
  - transforms: default
  - loss: cosine
  - dist_fn: cosine
  - optimizer: adamw

batch_size: 32
epochs: 100
validation_interval: 2
validations_without_improvement: 5
epoch_swap_to_hard: 5
epoch_swap_to_batch_hard: 20
best_model_path: "best.ckpt"
min_samples_per_id: 8   # only for semihard pretraining, then gets set to batch size

# If null, training is done from scratch
restore_model: null